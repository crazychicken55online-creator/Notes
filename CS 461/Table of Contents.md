[[Lecture 1]]
- [[Lecture 1#Why Machine Learning?|Why Machine Learning?]]
- [[Lecture 1#What is Machine Learning?|What is Machine Learning?]]
	- [[Lecture 1#What is Learning?|What is Learning?]]
	- [[Lecture 1#Example of the Learning Process|Example of the Learning Process]]
		- [[Lecture 1#A Block-Arch Scenario|Block-Arch Scenario]]
		- [[Lecture 1#A Block-Arch Scenario Observation of “Hand Change”|A Block-Arch Scenario Observation of “Hand Change”]]
		- [[Lecture 1#Visualizing an Arch Given New Data|Visualizing an Arch Given New Data]]
	- [[Lecture 1#What is Machine Learning?|What is Machine Learning?]]
		- [[Lecture 1#A machine can learn in 2 ways|A machine can learn in 2 ways]]
		- [[Lecture 1#Machine Learning as a heuristic solution for classification|Machine Learning as a heuristic solution for classification]]
	- [[Lecture 1#The Early Example of Machine Learning|The Early Example of Machine Learning]]
		- [[Lecture 1#The MIT Learning Machine (1950)|The MIT Learning Machine (1950)]]
		- [[Lecture 1#Theseus Operation Maze Solving Machine|Theseus Operation Maze Solving Machine]]
		- [[Lecture 1#Why is Theseus a Learning Machine|Why is Theseus a Learning Machine]]
		- [[Lecture 1#Definition of Machine Learning|Definition of Machine Learning]]
- [[Lecture 1#Machine Learning Principles|Machine Learning Principles]]
- [[Lecture 1#Machine Learning and AI|Machine Learning and AI]]
	- [[Lecture 1#Birth of AI in 1956|Birth of AI in 1956]]
- [[Lecture 1#Two Poles in AI Heuristic vs. Symbolic Approach|Two Poles in AI Heuristic vs. Symbolic Approach]]
	- [[Lecture 1#Connectionism (Heuristic Approach)|Connectionism (Heuristic Approach)]]
	- [[Lecture 1#Symbolic AI (Rule Based)|Symbolic AI (Rule Based)]]
[[Lecture 2]]
- [[Lecture 2#Why Probability?|Why Probability?]]
    - [[Lecture 2#To Measure Uncertainty|To Measure Uncertainty]]
    - [[Lecture 2#Why Probability in Machine Learning?|Why Probability in Machine Learning?]]
- [[Lecture 2#Two Interpretation of Probability Frequentist vs Bayesian|Two Interpretation of Probability: Frequentist vs Bayesian]]
    - [[Lecture 2#Simple Breakdown|Simple Breakdown]]
    - [[Lecture 2#Difference in Approach|Difference in Approach]]
        - [[Lecture 2#Frequentist Approach|Frequentist Approach]]
        - [[Lecture 2#Bayesian Approach|Bayesian Approach]]
    - [[Lecture 2#Simple Takeaway|Simple Takeaway]]
- [[Lecture 2#Probability 101|Probability 101]]
    - [[Lecture 2#Probability Space|Probability Space]]
    - [[Lecture 2#Probability Axioms|Probability Axioms]]
    - [[Lecture 2#Probability Corollaries|Probability Corollaries]]
- [[Lecture 2#Random Variables/Random Vectors|Random Variables/Random Vectors]]
    - [[Lecture 2#Bernoulli Random Variable|Bernoulli Random Variable]]
    - [[Lecture 2#Binomial Random Variable|Binomial Random Variable]]
    - [[Lecture 2#Cumulative Distribution Function (CDF)|Cumulative Distribution Function (CDF)]]
    - [[Lecture 2#Probability Density Function (PDF)|Probability Density Function (PDF)]]
    - [[Lecture 2#Probability Mass Function (PMF)|Probability Mass Function (PMF)]]
    - [[Lecture 2#Random Vectors|Random Vectors]]
- [[Lecture 2#Computing Probability Joint & Conditional Probabilities/Marginalization|Computing Probability: Joint & Conditional Probabilities/Marginalization]]
    - [[Lecture 2#Equally Likely Outcomes|Equally Likely Outcomes]]
    - [[Lecture 2#Biased Outcomes|Biased Outcomes]]
    - [[Lecture 2#Conditional Probability|Conditional Probability]]
    - [[Lecture 2#Joint Probability|Joint Probability]]
    - [[Lecture 2#Chain Rule|Chain Rule]]
    - [[Lecture 2#Independent Events|Independent Events]]
    - [[Lecture 2#Law of Total Probability (Partitioning)|Law of Total Probability (Partitioning)]]
- [[Lecture 2#Bayes Rules|Bayes Rules]]
- [[Lecture 2#Important Statistics mean & variance (random scalar & vectors)|Important Statistics: mean & variance (random scalar & vectors)]]
    - [[Lecture 2#Expected Value (Mean) - $ text{E[X]}$|Expected Value (Mean) - E(X)]]
    - [[Lecture 2#Variance - $Var(X)$|Variance - $Var(X)$]]
    - [[Lecture 2#Standard Deviation - $σ$ (sigma)|Standard Deviation - $σ$ (sigma)]]
    - [[Lecture 2#Covariance - $Cov(X, Y)$|Covariance - $Cov(X, Y)$]]
    - [[Lecture 2#Correlation - $ρ$ (rho)|Correlation - $ρ$ (rho)]]
    - [[Lecture 2#Variance of a Sum|Variance of a Sum]]
    - [[Lecture 2#Mean Vector - $μ$|Mean Vector - $μ$]]
    - [[Lecture 2#Covariance Matrix - $ Sigma$ (Sigma)|Covariance Matrix - $\Sigma$ (Sigma)]]
- [[Lecture 2#Gaussian Density (defined by mean and variance)|Gaussian Density (defined by mean and variance)]]
    - [[Lecture 2#The Central Limit Theorem (CLT)|The Central Limit Theorem (CLT)]]
    - [[Lecture 2#The Gaussian (Normal) Distribution|The Gaussian (Normal) Distribution]]
        - [[Lecture 2#Univariate Gaussian (1D)|Univariate Gaussian (1D)]]
        - [[Lecture 2#Multivariate Gaussian (Multidimensional)|Multivariate Gaussian (Multidimensional)]]
- [[Lecture 2#Maximum Likelihood Estimation (MLE)|Maximum Likelihood Estimation (MLE)]]
        - [[Lecture 2#Learning from Data|Learning from Data]]
        - [[Lecture 2##### The Likelihood Function|#### The Likelihood Function]]
        - [[Lecture 2#The MLE Process|The MLE Process]]
        - [[Lecture 2#MLE for Gaussian Mean|MLE for Gaussian Mean]]
- [[Lecture 2#Sample mean and Sample Variance|Sample mean and Sample Variance]]
        - [[Lecture 2#Sample Mean ($M n$)|Sample Mean ($M_n$)]]
        - [[Lecture 2#Sample Variance ($S^{2}$ or $V n$)|Sample Variance ($S^{2}$ or $V_n$)]]
        - [[Lecture 2#The Data Matrix ($D$)|The Data Matrix ($D$)]]
        - [[Lecture 2#Sample Mean Vector ($M$)|Sample Mean Vector ($M$)]]
        - [[Lecture 2#Sample Covariance ($C$)|Sample Covariance ($C$)]]